{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "##funkcije"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, accuracy_score, classification_report\n",
    "from sklearn.metrics import precision_recall_curve, confusion_matrix, plot_confusion_matrix, roc_curve, auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Korisni termini:\n",
    "<ul>\n",
    "    <li><em>True positives (TP)</em>: transakcije koje su prevare i naš model ih je ispravno klasificirao (kao prevare)</li>\n",
    "    <li><em>False positives (FP)</em>: transakcije koje su valjane, ali naš model ih je pogrešno klasificirao (kao prevare)</li>\n",
    "    <li><em>True negatives (TN)</em>: transakcije koje su valjane i naš model ih je ispravno klasificirao (kao valjane)</li>\n",
    "    <li><em>False negatives (FN)</em>: transakcije koje su prevare, ali naš model ih je pogrešno klasificirao (kao valjane)</li> <br>\n",
    "    <li><em>Precision (hrv. preciznost, oznaka: <i>P</i>)</em> -  omjer transakcija koje je model ispravno klasificirao kao prevare i svih transakcija koje je klasificirao kao prevare. Formulom: $P = \\frac{TP}{TP + FP}$</li>\n",
    "    <li><em>Recall (hrv. osjetljivost, oznaka: <i>R</i>)</em> -  omjer transakcija koje je model ispravno klasificirao kao prevare i svih transakcija koje ustvari jesu prevare. Formulom: $R = \\frac{TP}{TP + FN}$</li>\n",
    "    <li><em>F1-score(hrv. f1-mjera, oznaka: <i>F1</i>)</em> - mjera koja povezuje preciznost i osjetljivost formulom: $F1 = \\frac{2PR}{P + R}$</li>\n",
    "</ul>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sljedeću funkciju koristit ćemo da bi ispisali preciznost, osjetljivost i f1-mjeru. Primjetimo da ih ne trebamo računati ručno po formulama koje smo naveli, već ćemo samo koristiti funkcije implementirane u biblioteci <i>sklearn.metrics</i>. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_recall_f1_scores(correct, predicted):\n",
    "    print('\\tPrecision score: ' + str(round(precision_score(correct, predicted), 4) * 100) + '%')\n",
    "    print('\\tRecall score: ' + str(round(recall_score(correct, predicted), 4) * 100) + '%')\n",
    "    print('\\tF1 score: ' + str(round(f1_score(correct, predicted), 4) * 100) + '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Također da bi bolje procijenili 'kvalitetu' našeg modela crtamo i konfuzijsku matricu (odnosno 2). Lijeva konfuzijska matrica će nam služiti da bi izvukli čiste brojčane vrijednosti (primjerice koliko smo prevara ispravno klasificirali - dolje desno), dok ćemo desnu konfuzijsku matricu koristiti da bi dobili relativne vrijednosti (primjerice postotak ispravno klasificiranih prevara - isto dolje desno). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(conf_mat, y_test_non_fraud, y_test_fraud):\n",
    "    fig, ax = plt.subplots(1,2,figsize=(15,6))\n",
    "    labels = ['Valjana', 'Prevara']\n",
    "    ax[0].set_title('Konfuzijska matrica')\n",
    "    sns.heatmap(conf_mat, ax=ax[0], linewidths=0.5, annot=True,\n",
    "            square=True, cmap = plt.cm.coolwarm, linecolor='white',\n",
    "               xticklabels=labels, yticklabels=labels)\n",
    "    \n",
    "    \n",
    "    ax[1].set_title('Normalizirana konfuzijska matrica')\n",
    "    norm_coef = np.array([[1/y_test_non_fraud, 1/y_test_non_fraud],\n",
    "                         [1/y_test_fraud, 1/y_test_fraud]])\n",
    "    normalized_cm = conf_mat * norm_coef \n",
    "    sns.heatmap(normalized_cm, ax=ax[1], linewidths=0.5, annot=True,\n",
    "            square=True, cmap = plt.cm.coolwarm, linecolor='white',\n",
    "               xticklabels=labels, yticklabels=labels)\n",
    "    \n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kao zadnju metriku ćemo koristiti roc krivulju te PR krivulju. Doduše njih možemo nacrtati samo za logističku regresiju. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_auc_curve(correct, predicted):\n",
    "    fpr, tpr, threshold = roc_curve(correct, predicted)\n",
    "    area_under_curve = auc(fpr,tpr)\n",
    "    plt.plot([0, 1], [0, 1], \"k--\")\n",
    "    plt.plot(fpr, tpr, label=\"AUC = \" + str(round(area_under_curve,3)))\n",
    "    plt.xlabel(\"False positive rate\")\n",
    "    plt.ylabel(\"True positive rate\")\n",
    "    plt.title(\"ROC curve\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_precision_recall_curve(correct, predicted):\n",
    "    precision, recall, threshold = precision_recall_curve(correct, predicted)\n",
    "    aupr = auc(recall, precision)\n",
    "    plt.step(recall, precision, color = 'b', alpha = 0.2,\n",
    "             where = 'post')\n",
    "    plt.fill_between(recall, precision, step ='post', alpha = 0.2,\n",
    "                 color = 'b')\n",
    "\n",
    "    plt.plot(recall, precision, linewidth=2, label=\"AUC = \" + str(round(aupr,3)))\n",
    "    plt.xlim([0,1])\n",
    "    plt.ylim([0,1])\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title('Precision Recall Curve')\n",
    "    plt.legend()\n",
    "    plt.show();\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Još ćemo dodati funkciju <i>print_everything</i> koja nam omogućuje da u jednom retku ispišemo sve ranije navedene funkcije."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_everything(y_data_test, full_pred, non_frauds, frauds, full_pred_score, log_reg_bool):\n",
    "    print('-'*100)\n",
    "    print('Predikcija za cijeli dataset:')\n",
    "    precision_recall_f1_scores(y_data_test, full_pred)\n",
    "    print()\n",
    "    print('-'*100)\n",
    "    print(classification_report(y_data_test, full_pred))\n",
    "    print()\n",
    "    print('-'*100)\n",
    "    plot_confusion_matrix(confusion_matrix(y_data_test, full_pred), y_data_test_non_fraud_num, y_data_test_fraud_num)\n",
    "    print('-'*100)\n",
    "    \n",
    "    if log_reg_bool:\n",
    "        plot_roc_auc_curve(y_data_test, full_pred_score)\n",
    "        plot_precision_recall_curve(y_data_test, full_pred_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
